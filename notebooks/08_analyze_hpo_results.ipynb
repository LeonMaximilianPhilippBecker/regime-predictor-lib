{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import logging\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(\"HPO_Analysis_Notebook\")\n",
    "\n",
    "PROJECT_ROOT_PATH = Path.cwd().parent\n",
    "if str(PROJECT_ROOT_PATH / 'src') not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT_PATH / 'src'))\n",
    "\n",
    "required_packages = {\n",
    "    \"pandas\": \"pandas\",\n",
    "    \"numpy\": \"numpy\",\n",
    "    \"matplotlib\": \"matplotlib\",\n",
    "    \"seaborn\": \"seaborn\",\n",
    "    \"yaml\": \"pyyaml\",\n",
    "    \"optuna\": \"optuna\",\n",
    "    \"joblib\": \"joblib\",\n",
    "    \"plotly\": \"plotly\" \n",
    "}\n",
    "\n",
    "for package_name, install_name in required_packages.items():\n",
    "    try:\n",
    "        __import__(package_name)\n",
    "        logger.info(f\"Package '{package_name}' is already installed.\")\n",
    "    except ImportError:\n",
    "        logger.warning(f\"Module '{package_name}' not found. Attempting to install '{install_name}'...\")\n",
    "        try:\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\", install_name])\n",
    "            logger.info(f\"Package '{install_name}' installed successfully.\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to install '{install_name}': {e}\")\n",
    "            logger.error(f\"Please install it manually in your environment (e.g., `pip install {install_name}`) and restart the Jupyter kernel.\")\n",
    "            raise\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "import optuna\n",
    "import joblib\n",
    "\n",
    "HPO_RESULTS_DIR = PROJECT_ROOT_PATH / \"data\" / \"hpo_results\"\n",
    "HPO_SEARCH_SPACE_PATH = PROJECT_ROOT_PATH / \"config\" / \"supervised_learning\" / \"hpo_search_space.yaml\"\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"viridis\")\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "print(\"\\nSetup complete. All packages are installed and paths are configured.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hpo_results(hpo_dir: Path) -> pd.DataFrame:\n",
    "    all_results = []\n",
    "    if not hpo_dir.exists():\n",
    "        print(f\"Warning: HPO results directory not found at {hpo_dir}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    for json_file in hpo_dir.glob(\"*.json\"):\n",
    "        try:\n",
    "            parts = json_file.stem.split('_')\n",
    "            model_type = parts[-3] \n",
    "            theme_name = \"_\".join(parts[:-3])\n",
    "            \n",
    "            with open(json_file, 'r') as f:\n",
    "                params = json.load(f)\n",
    "            \n",
    "            result = {\n",
    "                \"theme\": theme_name,\n",
    "                \"model_type\": model_type,\n",
    "                **params\n",
    "            }\n",
    "            all_results.append(result)\n",
    "        except (IndexError, json.JSONDecodeError) as e:\n",
    "            print(f\"Could not process file {json_file.name}: {e}\")\n",
    "            continue\n",
    "            \n",
    "    if not all_results:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    return pd.DataFrame(all_results)\n",
    "\n",
    "hpo_results_df = load_hpo_results(HPO_RESULTS_DIR)\n",
    "\n",
    "with open(HPO_SEARCH_SPACE_PATH, 'r') as f:\n",
    "    hpo_search_spaces = yaml.safe_load(f)\n",
    "\n",
    "print(f\"Loaded {len(hpo_results_df)} HPO results.\")\n",
    "hpo_results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def plot_optimization_histories_for_model(model_type: str):\n",
    "    \n",
    "    study_files = list(HPO_RESULTS_DIR.glob(f\"*_{model_type}_study.pkl\"))\n",
    "    if not study_files:\n",
    "        print(f\"No study .pkl files found for model type '{model_type}'.\")\n",
    "        return\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "    for study_file in study_files:\n",
    "        study = joblib.load(study_file)\n",
    "        theme_name = study_file.stem.split(f'_{model_type}_study')[0]\n",
    "        \n",
    "        trial_numbers = [t.number for t in study.trials]\n",
    "        best_values = [t.user_attrs.get('best_value_so_far', t.value) for t in study.trials] \n",
    "        \n",
    "        values = [t.value for t in study.trials]\n",
    "        best_values_so_far = np.minimum.accumulate(values)\n",
    "        \n",
    "        ax.plot(trial_numbers, best_values_so_far, label=theme_name, alpha=0.7, lw=2)\n",
    "\n",
    "    ax.set_title(f'Optimization History for {model_type.upper()} Models', fontsize=16)\n",
    "    ax.set_xlabel('Trial Number', fontsize=12)\n",
    "    ax.set_ylabel('Best Objective Value (LogLoss) So Far', fontsize=12)\n",
    "    ax.legend(title='Thematic Pipeline', bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "    ax.grid(True, which='both', linestyle='--')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_optimization_histories_for_model('xgboost')\n",
    "plot_optimization_histories_for_model('lightgbm_dart')\n",
    "plot_optimization_histories_for_model('catboost')"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hyperparameter_distributions(model_type: str):\n",
    "    \n",
    "    if model_type not in hpo_results_df['model_type'].unique():\n",
    "        print(f\"No HPO results found for model type: {model_type}\")\n",
    "        return\n",
    "\n",
    "    model_df = hpo_results_df[hpo_results_df['model_type'] == model_type]\n",
    "    \n",
    "    params_to_plot = list(hpo_search_spaces.get(model_type, {}).keys())\n",
    "    if not params_to_plot:\n",
    "        print(f\"No hyperparameters defined in search space for {model_type}\")\n",
    "        return\n",
    "    \n",
    "    categorical_params = [p for p in params_to_plot if hpo_search_spaces[model_type][p]['type'] == 'categorical']\n",
    "    numerical_params = [p for p in params_to_plot if p not in categorical_params]\n",
    "    \n",
    "    if numerical_params:\n",
    "        num_plots = len(numerical_params)\n",
    "        num_cols = 3\n",
    "        num_rows = (num_plots - 1) // num_cols + 1\n",
    "        fig, axes = plt.subplots(num_rows, num_cols, figsize=(16, 4 * num_rows), squeeze=False)\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        fig.suptitle(f'Distribution of Tuned Numerical Hyperparameters for {model_type.upper()}', fontsize=18, y=1.02)\n",
    "        \n",
    "        for i, param in enumerate(numerical_params):\n",
    "            if param in model_df.columns:\n",
    "                sns.boxplot(x=model_df[param], ax=axes[i])\n",
    "                sns.stripplot(x=model_df[param], ax=axes[i], color='black', alpha=0.5, size=5)\n",
    "                axes[i].set_title(f'{param}', fontsize=12)\n",
    "                axes[i].set_xlabel('Value')\n",
    "        \n",
    "        for j in range(i + 1, len(axes)):\n",
    "            fig.delaxes(axes[j])\n",
    "            \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "        plt.show()\n",
    "        \n",
    "    if categorical_params:\n",
    "        num_plots = len(categorical_params)\n",
    "        fig, axes = plt.subplots(1, num_plots, figsize=(6 * num_plots, 5), squeeze=False)\n",
    "        axes = axes.flatten()\n",
    "        fig.suptitle(f'Distribution of Tuned Categorical Hyperparameters for {model_type.upper()}', fontsize=18, y=1.02)\n",
    "        \n",
    "        for i, param in enumerate(categorical_params):\n",
    "            if param in model_df.columns:\n",
    "                sns.countplot(y=model_df[param], ax=axes[i], palette='crest')\n",
    "                axes[i].set_title(f'{param}', fontsize=12)\n",
    "                axes[i].set_xlabel('Count')\n",
    "                axes[i].set_ylabel('')\n",
    "                \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.94])\n",
    "        plt.show()\n",
    "\n",
    "for model_t in hpo_results_df['model_type'].unique():\n",
    "    plot_hyperparameter_distributions(model_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_advanced_hpo_analysis(model_type: str):\n",
    "    study_files = list(HPO_RESULTS_DIR.glob(f\"*_{model_type}_study.pkl\"))\n",
    "    if not study_files:\n",
    "        print(f\"Skipping advanced analysis for '{model_type}': No study .pkl files found.\")\n",
    "        return\n",
    "    \n",
    "    first_study_path = study_files[0]\n",
    "    study = joblib.load(first_study_path)\n",
    "    theme_name = first_study_path.stem.split(f'_{model_type}_study')[0]\n",
    "    \n",
    "    print(f\"\\n--- Advanced Analysis for {model_type.upper()} (Example from theme: {theme_name}) ---\")\n",
    "\n",
    "    try:\n",
    "        fig_imp = optuna.visualization.plot_param_importances(study)\n",
    "        fig_imp.update_layout(title=f'Hyperparameter Importance for {model_type}')\n",
    "        fig_imp.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Could not generate importance plot: {e}\")\n",
    "\n",
    "    try:\n",
    "        fig_pc = optuna.visualization.plot_parallel_coordinate(study)\n",
    "        fig_pc.update_layout(title=f'Parallel Coordinate Plot for {model_type}')\n",
    "        fig_pc.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Could not generate parallel coordinate plot: {e}\")\n",
    "        \n",
    "    try:\n",
    "        most_important_param = study.best_params.keys()\n",
    "        if most_important_param:\n",
    "            param_to_slice = list(most_important_param)[0]\n",
    "            fig_slice = optuna.visualization.plot_slice(study, params=[param_to_slice])\n",
    "            fig_slice.update_layout(title=f'Slice Plot for `{param_to_slice}` in {model_type}')\n",
    "            fig_slice.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Could not generate slice plot: {e}\")\n",
    "\n",
    "\n",
    "for model_t in hpo_results_df['model_type'].unique():\n",
    "    run_advanced_hpo_analysis(model_t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
