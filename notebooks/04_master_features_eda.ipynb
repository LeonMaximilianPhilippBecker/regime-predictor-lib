{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# EDA of Master Features Table\n",
    "\n",
    "This notebook performs an exploratory data analysis on the `master_features` table\n",
    "generated by the feature engineering pipeline. The goal is to understand the\n",
    "characteristics of the features, their distributions, relationships, and how they\n",
    "relate to the identified market regimes."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c8f128b59355e24e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sqlalchemy\n",
    "import yaml\n",
    "import warnings\n",
    "\n",
    "PROJECT_ROOT_PATH = Path.cwd().parent \n",
    "if str(PROJECT_ROOT_PATH) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT_PATH))\n",
    "if str(PROJECT_ROOT_PATH / \"src\") not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT_PATH / \"src\"))\n",
    "\n",
    "from regime_predictor_lib.utils.database_manager import DatabaseManager\n",
    "\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning) \n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6) \n",
    "plt.rcParams['savefig.dpi'] = 300 \n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.width', 1000)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "34f58584926bc4bb",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Setup & Data Loading"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6ce2bcb0b0bf915"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "DB_NAME = \"quant.db\"\n",
    "DB_VOLUME_PATH = PROJECT_ROOT_PATH / \"data\" / \"db\" / \"volume\"\n",
    "DB_PATH = DB_VOLUME_PATH / DB_NAME\n",
    "MASTER_FEATURES_TABLE_NAME = \"master_features\"\n",
    "COLUMN_ANALYSIS_YAML_PATH = PROJECT_ROOT_PATH / \"data\" / \"processed\" / \"master_features_column_analysis.yaml\"\n",
    "\n",
    "EDA_REPORTS_DIR = PROJECT_ROOT_PATH / \"data\" / \"reports\" / \"eda\" / \"master_features\"\n",
    "EDA_REPORTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "COV_CORR_DIR = EDA_REPORTS_DIR / \"covariance_correlation\"\n",
    "COV_CORR_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "UNIVARIATE_DIR = EDA_REPORTS_DIR / \"univariate_analysis\"\n",
    "UNIVARIATE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "VINTAGE_LAG_DIR = EDA_REPORTS_DIR / \"vintage_lag_analysis\"\n",
    "VINTAGE_LAG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "db_manager = DatabaseManager(db_path=DB_PATH)\n",
    "\n",
    "try:\n",
    "    engine = db_manager.engine\n",
    "    query = f\"SELECT * FROM {MASTER_FEATURES_TABLE_NAME} ORDER BY date ASC\"\n",
    "    mf_df = pd.read_sql_query(sql=sqlalchemy.text(query), con=engine, parse_dates=['date'])\n",
    "    mf_df.set_index('date', inplace=True)\n",
    "    print(f\"Successfully loaded '{MASTER_FEATURES_TABLE_NAME}' table. Shape: {mf_df.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading '{MASTER_FEATURES_TABLE_NAME}' table: {e}\")\n",
    "    mf_df = pd.DataFrame()\n",
    "\n",
    "column_analysis = None\n",
    "if COLUMN_ANALYSIS_YAML_PATH.exists():\n",
    "    try:\n",
    "        with open(COLUMN_ANALYSIS_YAML_PATH, 'r') as f:\n",
    "            column_analysis = yaml.safe_load(f)\n",
    "        print(f\"Successfully loaded column analysis from: {COLUMN_ANALYSIS_YAML_PATH.name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading column analysis YAML: {e}\")\n",
    "else:\n",
    "    print(f\"Column analysis YAML not found at: {COLUMN_ANALYSIS_YAML_PATH}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dedef7802fcd5f8",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Initial Overview & Sanity Checks"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eaa30b4c8949b4bd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if not mf_df.empty:\n",
    "    print(\"--- Head (first 5 rows) ---\")\n",
    "    display(mf_df.head())\n",
    "    print(f\"\\nDataFrame shape: {mf_df.shape}\")\n",
    "    \n",
    "    print(\"\\n--- Info (condensed) ---\")\n",
    "    mf_df.info(verbose=False) \n",
    "\n",
    "    print(\"\\n--- Saving full .describe() to CSV ---\")\n",
    "    describe_df = mf_df.describe(include='all').transpose()\n",
    "    describe_df.to_csv(EDA_REPORTS_DIR / \"master_features_describe_full.csv\")\n",
    "    print(f\"Full describe saved to: {EDA_REPORTS_DIR / 'master_features_describe_full.csv'}\")\n",
    "    print(\"Sample of describe:\")\n",
    "    display(describe_df.head())\n",
    "else:\n",
    "    print(\"Master features DataFrame is empty. Cannot perform EDA.\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28244ae422d6714d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if not mf_df.empty:\n",
    "    nan_summary_after_imputation = mf_df.isnull().sum().sort_values(ascending=False)\n",
    "    nan_percentage_after_imputation = (mf_df.isnull().sum() / len(mf_df) * 100).sort_values(ascending=False)\n",
    "    \n",
    "    nan_df_summary = pd.DataFrame({\n",
    "        'NaN Count': nan_summary_after_imputation,\n",
    "        'NaN Percentage': nan_percentage_after_imputation\n",
    "    })\n",
    "    nan_df_summary.to_csv(EDA_REPORTS_DIR / \"master_features_nan_summary.csv\")\n",
    "    print(f\"\\nFull NaN summary saved to: {EDA_REPORTS_DIR / 'master_features_nan_summary.csv'}\")\n",
    "    \n",
    "    print(\"\\n--- NaN Summary (Top 20 with NaNs) ---\")\n",
    "    display(nan_df_summary[nan_df_summary['NaN Count'] > 0].head(20))\n",
    "\n",
    "    numeric_cols = mf_df.select_dtypes(include=np.number).columns.tolist()\n",
    "    object_cols = mf_df.select_dtypes(include='object').columns.tolist()\n",
    "    print(f\"\\nIdentified {len(numeric_cols)} numeric columns.\")\n",
    "    print(f\"Identified {len(object_cols)} object/categorical columns (sample): {object_cols[:10] if object_cols else 'None'}...\")\n",
    "else:\n",
    "    print(\"Master features DataFrame is empty.\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e6ee9f962212bb6",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Target Variable Analysis (`regime_t`, `regime_t_plus_6m`)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e43fd5391b081ef"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "target_cols = ['regime_t', 'regime_t_plus_6m']\n",
    "if not mf_df.empty and all(col in mf_df.columns for col in target_cols):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    sns.countplot(x='regime_t', data=mf_df.dropna(subset=['regime_t']), ax=axes[0], palette='viridis')\n",
    "    axes[0].set_title('Distribution of Current Regime (regime_t)')\n",
    "    axes[0].set_xlabel('Regime State')\n",
    "    axes[0].set_ylabel('Count')\n",
    "\n",
    "    sns.countplot(x='regime_t_plus_6m', data=mf_df.dropna(subset=['regime_t_plus_6m']), ax=axes[1], palette='viridis')\n",
    "    axes[1].set_title('Distribution of Future Regime (regime_t_plus_6m)')\n",
    "    axes[1].set_xlabel('Regime State')\n",
    "    axes[1].set_ylabel('Count')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(EDA_REPORTS_DIR / \"target_variable_distributions.png\")\n",
    "    plt.show()\n",
    "\n",
    "    df_for_transition = mf_df[target_cols].dropna()\n",
    "    if not df_for_transition.empty:\n",
    "        df_for_transition['regime_t'] = df_for_transition['regime_t'].astype(int)\n",
    "        df_for_transition['regime_t_plus_6m'] = df_for_transition['regime_t_plus_6m'].astype(int)\n",
    "\n",
    "        transition_counts = pd.crosstab(df_for_transition['regime_t'], df_for_transition['regime_t_plus_6m'])\n",
    "        transition_probs = transition_counts.apply(lambda r: r/r.sum(), axis=1)\n",
    "        \n",
    "        transition_probs.to_csv(EDA_REPORTS_DIR / \"regime_transition_probabilities.csv\")\n",
    "        print(f\"Regime transition probabilities saved to: {EDA_REPORTS_DIR / 'regime_transition_probabilities.csv'}\")\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(transition_probs, annot=True, fmt=\".2f\", cmap=\"Blues\")\n",
    "        plt.title('Transition Probabilities: regime_t to regime_t_plus_6m')\n",
    "        plt.xlabel('Regime (t + 6m)')\n",
    "        plt.ylabel('Regime (t)')\n",
    "        plt.savefig(EDA_REPORTS_DIR / \"regime_transition_heatmap.png\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Not enough data to compute transition matrix.\")\n",
    "else:\n",
    "    print(f\"Target columns ({', '.join(target_cols)}) not found or DataFrame is empty.\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1846ecd99e16a0ce",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Global Feature Statistics"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d8e59d0dd896b964"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "PREFIX_THEME_MAP_FOR_MASTER = {\n",
    "    \"ti_gspc_\": \"1. Technicals (S&P500)\",\n",
    "    \"vol_\": \"2. Volatility & Stress\",\n",
    "    \"pcr_\": \"3. Market Internals (PCR)\",\n",
    "    \"breadth_\": \"3. Market Internals (Breadth)\",\n",
    "    \"stk_bond_diff_\": \"4. Intermarket (Stock/Bond Diff)\",\n",
    "    \"spy_tlt_ratio_\": \"4. Intermarket (SPY/TLT Ratio)\", \n",
    "    \"gold_silver_ratio_\": \"4. Intermarket (Gold/Silver Ratio)\",\n",
    "    \"copper_gold_ratio_\": \"4. Intermarket (Copper/Gold Ratio)\",\n",
    "    \"junk_spread_\": \"5. Credit & Bonds (Junk Spread)\",\n",
    "    \"corp_oas_\": \"5. Credit & Bonds (Corp OAS)\",\n",
    "    \"tsy_spread_\": \"5. Credit & Bonds (Treasury Spread)\",\n",
    "    \"em_tbill_spread_\": \"5. Credit & Bonds (EM/T-Bill Spread)\",\n",
    "    \"fg_\": \"6. Sentiment (Fear/Greed)\",\n",
    "    \"conf_\": \"6. Sentiment (Consumer Conf.)\",\n",
    "    \"aaii_\": \"6. Sentiment (AAII)\",\n",
    "    \"finra_\": \"6. Sentiment (FINRA Margin)\",\n",
    "    \"sentconf_\": \"6. Sentiment (SMCI/DMCI)\",\n",
    "    \"nfp_\": \"7. Macro (NFP)\",\n",
    "    \"icj_\": \"7. Macro (Jobless Claims)\",\n",
    "    \"cpi_\": \"7. Macro (CPI)\",\n",
    "    \"retail_\": \"7. Macro (Retail Sales)\",\n",
    "    \"m2_\": \"7. Macro (M2 Supply)\",\n",
    "    \"houst_\": \"7. Macro (Housing Starts)\",\n",
    "    \"hpi_\": \"7. Macro (Housing Prices)\",\n",
    "    \"smi_\": \"8. Market Structure (SMI)\",\n",
    "    \"djt_vs_gspc_\": \"9. Sector/Micro (DJT/GSPC)\", \n",
    "    \"rut_vs_gspc_\": \"9. Sector/Micro (RUT/GSPC)\",\n",
    "    \"qqq_vs_dju_\": \"9. Sector/Micro (QQQ/DJU)\",\n",
    "    \"xlv_vs_gspc_\": \"9. Sector/Micro (XLV/GSPC)\",\n",
    "    \"dxy_\": \"10. Global & Currency (DXY)\",\n",
    "    \"em_\": \"10. Global & Currency (EM Equity)\",\n",
    "    \"oil_\": \"10. Global & Currency (Oil)\",\n",
    "    \"bdi_\": \"10. Global & Currency (BDI)\",\n",
    "    \"gex_\": \"11. Derivatives (GEX)\",\n",
    "    \"sp500_\": \"0. S&P500 Base\", \n",
    "}\n",
    "\n",
    "def get_theme_for_column(col_name, prefix_map):\n",
    "    sorted_prefixes = sorted(prefix_map.keys(), key=len, reverse=True)\n",
    "    for prefix in sorted_prefixes:\n",
    "        if col_name.startswith(prefix):\n",
    "            return prefix_map[prefix]\n",
    "    if col_name.startswith(\"regime_\"):\n",
    "        return \"Market Regime Info\"\n",
    "    return \"Uncategorized\"\n",
    "\n",
    "if not mf_df.empty:\n",
    "    mf_df_numeric = mf_df[numeric_cols] \n",
    "    \n",
    "    features_by_theme = {}\n",
    "    for col in mf_df_numeric.columns:\n",
    "        theme = get_theme_for_column(col, PREFIX_THEME_MAP_FOR_MASTER)\n",
    "        if theme not in features_by_theme:\n",
    "            features_by_theme[theme] = []\n",
    "        features_by_theme[theme].append(col)\n",
    "    \n",
    "    print(\"Feature counts per identified theme:\")\n",
    "    for theme, cols in features_by_theme.items():\n",
    "        print(f\"- {theme}: {len(cols)} features\")\n",
    "    \n",
    "    themes_for_intra_analysis = {theme: cols for theme, cols in features_by_theme.items() if len(cols) >= 2}\n",
    "    print(f\"\\nThemes with >=2 features for intra-analysis: {len(themes_for_intra_analysis)}\")\n",
    "\n",
    "else:\n",
    "    print(\"mf_df is empty. Cannot categorize features by theme.\")\n",
    "    features_by_theme = {}\n",
    "    themes_for_intra_analysis = {}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eedb302cf4468a97",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.05 Intra-Category Covariance & Correlation Matrices\n",
    "For each thematic group of features, we'll compute and save their internal covariance and correlation matrices."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6d1c2e27c18214d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "INTRA_CATEGORY_DIR = COV_CORR_DIR / \"by_theme\"\n",
    "INTRA_CATEGORY_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not mf_df.empty and themes_for_intra_analysis:\n",
    "    print(f\"\\n--- Generating Intra-Category Covariance & Correlation Matrices ---\")\n",
    "    for theme, theme_cols in themes_for_intra_analysis.items():\n",
    "        print(f\"  Processing theme: {theme} ({len(theme_cols)} features)\")\n",
    "        \n",
    "        safe_theme_name = theme.replace(\"&\", \"and\").replace(\"/\", \"_\").replace(\" \", \"_\").lower()\n",
    "        theme_output_dir = INTRA_CATEGORY_DIR / safe_theme_name\n",
    "        theme_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        temp_df_theme = mf_df_numeric[theme_cols].copy()\n",
    "        \n",
    "        temp_df_theme.dropna(axis=1, how='all', inplace=True)\n",
    "        theme_variances = temp_df_theme.var(ddof=0)\n",
    "        theme_cols_with_variance = theme_variances[theme_variances > 1e-9].index.tolist()\n",
    "        \n",
    "        if len(theme_cols_with_variance) < 2:\n",
    "            print(f\"    Skipping theme '{theme}' due to < 2 features with variance.\")\n",
    "            continue\n",
    "            \n",
    "        temp_df_theme_final = temp_df_theme[theme_cols_with_variance]\n",
    "\n",
    "        cov_matrix_theme = temp_df_theme_final.cov()\n",
    "        cov_matrix_theme.to_csv(theme_output_dir / f\"{safe_theme_name}_covariance_matrix.csv\")\n",
    "        \n",
    "        fig_width = max(10, len(theme_cols_with_variance) * 0.4)\n",
    "        fig_height = max(8, len(theme_cols_with_variance) * 0.4)\n",
    "        plt.figure(figsize=(fig_width, fig_height))\n",
    "        sns.heatmap(cov_matrix_theme, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
    "        plt.title(f'Covariance Matrix: {theme}', fontsize=16)\n",
    "        plt.xticks(fontsize=8, rotation=90)\n",
    "        plt.yticks(fontsize=8, rotation=0)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(theme_output_dir / f\"{safe_theme_name}_covariance_heatmap.png\")\n",
    "        plt.close()\n",
    "\n",
    "        corr_matrix_theme = temp_df_theme_final.corr()\n",
    "        corr_matrix_theme.to_csv(theme_output_dir / f\"{safe_theme_name}_correlation_matrix.csv\")\n",
    "\n",
    "        plt.figure(figsize=(fig_width, fig_height))\n",
    "        sns.heatmap(corr_matrix_theme, annot=True, cmap='coolwarm', center=0, vmin=-1, vmax=1, fmt=\".2f\", linewidths=.5)\n",
    "        plt.title(f'Correlation Matrix: {theme}', fontsize=16)\n",
    "        plt.xticks(fontsize=8, rotation=90)\n",
    "        plt.yticks(fontsize=8, rotation=0)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(theme_output_dir / f\"{safe_theme_name}_correlation_heatmap.png\")\n",
    "        plt.close()\n",
    "        \n",
    "    print(\"Intra-category matrices and heatmaps saved.\")\n",
    "else:\n",
    "    print(\"DataFrame is empty or no themes identified for intra-category analysis.\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6abf0c3bcfea0094",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.1 Covariance Matrix\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "54cb94776b39e70c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if not mf_df.empty and numeric_cols:\n",
    "    print(f\"Calculating Covariance Matrix for ALL {len(numeric_cols)} numeric features...\")\n",
    "    \n",
    "    temp_df_for_cov = mf_df[numeric_cols].dropna(axis=1, how='all')\n",
    "    variances = temp_df_for_cov.var(ddof=0) \n",
    "    cols_with_variance = variances[variances > 1e-9].index.tolist() \n",
    "    \n",
    "    if not cols_with_variance:\n",
    "        print(\"No numeric columns with sufficient variance found for covariance matrix.\")\n",
    "    else:\n",
    "        temp_df_for_cov_final = temp_df_for_cov[cols_with_variance]\n",
    "        print(f\"Using {len(cols_with_variance)} columns for covariance matrix.\")\n",
    "\n",
    "        covariance_matrix_full = temp_df_for_cov_final.cov()\n",
    "        covariance_matrix_full.to_csv(COV_CORR_DIR / \"full_covariance_matrix.csv\")\n",
    "        print(f\"Full covariance matrix saved to: {COV_CORR_DIR / 'full_covariance_matrix.csv'}\")\n",
    "\n",
    "        fig_width = max(20, len(cols_with_variance) * 0.25) \n",
    "        fig_height = max(18, len(cols_with_variance) * 0.25)\n",
    "        \n",
    "        plt.figure(figsize=(fig_width, fig_height))\n",
    "        sns.heatmap(covariance_matrix_full, annot=False, cmap='coolwarm', fmt=\".1f\")\n",
    "        plt.title('Covariance Matrix of Numerical Features', fontsize=20)\n",
    "        plt.xticks(fontsize=6, rotation=90) \n",
    "        plt.yticks(fontsize=6, rotation=0)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(COV_CORR_DIR / \"covariance_matrix_heatmap_full.png\", dpi=300)\n",
    "        plt.close() \n",
    "        print(f\"Covariance matrix heatmap saved to: {COV_CORR_DIR / 'covariance_matrix_heatmap_full.png'}\")\n",
    "\n",
    "        print(\"\\n--- Top 50 Highest Absolute Covariance Pairs (excluding self-covariance) ---\")\n",
    "        cov_unstacked = covariance_matrix_full.unstack()\n",
    "        cov_unstacked_sorted_abs = cov_unstacked[cov_unstacked.index.get_level_values(0) < cov_unstacked.index.get_level_values(1)].abs().sort_values(ascending=False)\n",
    "        top_abs_cov_pairs_signed = cov_unstacked.loc[cov_unstacked_sorted_abs.head(50).index]\n",
    "        top_abs_cov_pairs_signed.to_csv(COV_CORR_DIR / \"top_absolute_covariance_pairs.csv\", header=['covariance'])\n",
    "        display(top_abs_cov_pairs_signed.head(20))\n",
    "else:\n",
    "    print(\"No numeric columns available or DataFrame is empty for covariance matrix.\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f61d89cddd01d9d1",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.2 Correlation Matrix"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d19b1061e53c0631"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if not mf_df.empty and numeric_cols:\n",
    "    print(f\"\\nCalculating Correlation Matrix for ALL {len(numeric_cols)} numeric features...\")\n",
    "    if 'cols_with_variance' in locals() and cols_with_variance: \n",
    "        temp_df_for_corr = mf_df[cols_with_variance]\n",
    "        correlation_matrix_full = temp_df_for_corr.corr()\n",
    "        correlation_matrix_full.to_csv(COV_CORR_DIR / \"full_correlation_matrix.csv\")\n",
    "        print(f\"Full correlation matrix saved to: {COV_CORR_DIR / 'full_correlation_matrix.csv'}\")\n",
    "\n",
    "        fig_width = max(20, len(cols_with_variance) * 0.25)\n",
    "        fig_height = max(18, len(cols_with_variance) * 0.25)\n",
    "\n",
    "        plt.figure(figsize=(fig_width, fig_height))\n",
    "        sns.heatmap(correlation_matrix_full, annot=False, cmap='coolwarm', center=0, vmin=-1, vmax=1, fmt=\".1f\")\n",
    "        plt.title('Correlation Matrix of Numerical Features', fontsize=20)\n",
    "        plt.xticks(fontsize=6, rotation=90)\n",
    "        plt.yticks(fontsize=6, rotation=0)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(COV_CORR_DIR / \"correlation_matrix_heatmap_full.png\", dpi=300)\n",
    "        plt.close()\n",
    "        print(f\"Correlation matrix heatmap saved to: {COV_CORR_DIR / 'correlation_matrix_heatmap_full.png'}\")\n",
    "\n",
    "        print(\"\\n--- Top 50 Most Positively Correlated Pairs (excluding self-correlation) ---\")\n",
    "        corr_unstacked = correlation_matrix_full.unstack()\n",
    "        corr_unstacked_filtered = corr_unstacked[corr_unstacked.index.get_level_values(0) < corr_unstacked.index.get_level_values(1)]\n",
    "        \n",
    "        top_pos_corr = corr_unstacked_filtered.sort_values(ascending=False).head(50)\n",
    "        top_pos_corr.to_csv(COV_CORR_DIR / \"top_positive_correlation_pairs.csv\", header=['correlation'])\n",
    "        display(top_pos_corr.head(20))\n",
    "\n",
    "        print(\"\\n--- Top 50 Most Negatively Correlated Pairs ---\")\n",
    "        top_neg_corr = corr_unstacked_filtered.sort_values(ascending=True).head(50)\n",
    "        top_neg_corr.to_csv(COV_CORR_DIR / \"top_negative_correlation_pairs.csv\", header=['correlation'])\n",
    "        display(top_neg_corr.head(20))\n",
    "    else:\n",
    "        print(\"No numeric columns with sufficient variance found for correlation matrix.\")\n",
    "else:\n",
    "    print(\"No numeric columns available or DataFrame is empty for correlation matrix.\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "312893ca979ee214",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.3 Missing Data Patterns (Post-Imputation)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e516296197f959d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if not mf_df.empty:\n",
    "    fig_width_missing = max(20, mf_df.shape[1] * 0.1) \n",
    "    fig_height_missing = max(10, mf_df.shape[0] * 0.01) \n",
    "    fig_height_missing = min(fig_height_missing, 20) \n",
    "\n",
    "    plt.figure(figsize=(fig_width_missing, fig_height_missing))\n",
    "    sns.heatmap(mf_df.isnull(), cbar=False, cmap='viridis', yticklabels=False) \n",
    "    plt.title('Missing Data Pattern in Master Features (Yellow=Missing)', fontsize=16)\n",
    "    plt.ylabel('Date (Time Series Order)')\n",
    "    plt.xlabel('Features')\n",
    "    plt.xticks(fontsize=5, rotation=90) \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(EDA_REPORTS_DIR / \"missing_data_heatmap_full.png\", dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"Full missing data heatmap saved to: {EDA_REPORTS_DIR / 'missing_data_heatmap_full.png'}\")\n",
    "else:\n",
    "    print(\"DataFrame is empty, skipping missing data pattern visualization.\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8718d91039c701ff",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.4 Inter-Category Average Absolute Correlation Matrix\n",
    "This matrix will show the average absolute correlation *between* features of different thematic groups.\n",
    "Diagonal elements represent the average absolute *intra*-category correlation."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bfb6daa76449e032"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "INTER_CATEGORY_SUMMARY_DIR = COV_CORR_DIR / \"inter_category_summary\"\n",
    "INTER_CATEGORY_SUMMARY_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not mf_df.empty and themes_for_intra_analysis: \n",
    "    print(f\"\\n--- Generating Inter-Category Average Absolute Correlation Matrix ---\")\n",
    "    \n",
    "    if 'correlation_matrix_full' not in locals() or correlation_matrix_full.empty:\n",
    "        print(\"Full correlation matrix not available. Recomputing for inter-category analysis.\")\n",
    "        temp_df_for_corr = mf_df_numeric[cols_with_variance] \n",
    "        if not temp_df_for_corr.empty:\n",
    "            correlation_matrix_full = temp_df_for_corr.corr()\n",
    "        else:\n",
    "            print(\"Cannot compute full correlation matrix. Aborting inter-category analysis.\")\n",
    "            correlation_matrix_full = pd.DataFrame()\n",
    "\n",
    "\n",
    "    if not correlation_matrix_full.empty:\n",
    "        category_names = sorted(list(themes_for_intra_analysis.keys()))\n",
    "        avg_abs_corr_matrix = pd.DataFrame(index=category_names, columns=category_names, dtype=float)\n",
    "\n",
    "        for i, theme1_name in enumerate(category_names):\n",
    "            for j, theme2_name in enumerate(category_names):\n",
    "                if j < i: \n",
    "                    avg_abs_corr_matrix.loc[theme1_name, theme2_name] = avg_abs_corr_matrix.loc[theme2_name, theme1_name]\n",
    "                    continue\n",
    "\n",
    "                cols_theme1 = [col for col in themes_for_intra_analysis[theme1_name] if col in correlation_matrix_full.columns]\n",
    "                cols_theme2 = [col for col in themes_for_intra_analysis[theme2_name] if col in correlation_matrix_full.columns]\n",
    "\n",
    "                if not cols_theme1 or not cols_theme2:\n",
    "                    avg_abs_corr_matrix.loc[theme1_name, theme2_name] = np.nan\n",
    "                    continue\n",
    "                \n",
    "                if theme1_name == theme2_name: \n",
    "                    if len(cols_theme1) < 2:\n",
    "                        avg_abs_corr_matrix.loc[theme1_name, theme1_name] = np.nan \n",
    "                        continue\n",
    "                    sub_corr_matrix = correlation_matrix_full.loc[cols_theme1, cols_theme1]\n",
    "                    upper_triangle_mask = np.triu(np.ones(sub_corr_matrix.shape), k=1).astype(bool)\n",
    "                    relevant_corrs = sub_corr_matrix.where(upper_triangle_mask).stack().abs()\n",
    "                else: \n",
    "                    sub_corr_matrix = correlation_matrix_full.loc[cols_theme1, cols_theme2]\n",
    "                    relevant_corrs = sub_corr_matrix.stack().abs()\n",
    "                \n",
    "                if not relevant_corrs.empty:\n",
    "                    avg_abs_corr_matrix.loc[theme1_name, theme2_name] = relevant_corrs.mean()\n",
    "                else:\n",
    "                    avg_abs_corr_matrix.loc[theme1_name, theme2_name] = np.nan\n",
    "        \n",
    "        avg_abs_corr_matrix.to_csv(INTER_CATEGORY_SUMMARY_DIR / \"inter_category_avg_abs_correlation.csv\")\n",
    "        print(f\"Inter-category average absolute correlation matrix saved to CSV.\")\n",
    "\n",
    "        plt.figure(figsize=(max(12, len(category_names)*0.8), max(10, len(category_names)*0.7)))\n",
    "        sns.heatmap(avg_abs_corr_matrix.astype(float), annot=True, cmap=\"viridis\", fmt=\".2f\", linewidths=.5)\n",
    "        plt.title('Inter-Category Average Absolute Correlation', fontsize=16)\n",
    "        plt.xticks(fontsize=10, rotation=90)\n",
    "        plt.yticks(fontsize=10, rotation=0)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(INTER_CATEGORY_SUMMARY_DIR / \"inter_category_avg_abs_correlation_heatmap.png\")\n",
    "        plt.close()\n",
    "        print(f\"Inter-category average absolute correlation heatmap saved.\")\n",
    "        \n",
    "        print(\"\\n--- Inter-Category Average Absolute Correlation Matrix (Sample) ---\")\n",
    "        display(avg_abs_corr_matrix.head())\n",
    "\n",
    "else:\n",
    "    print(\"DataFrame is empty or no themes for analysis, skipping inter-category correlations.\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b77c92940daa29",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "PREFIX_THEME_MAP_FOR_MASTER = {\n",
    "    \"ti_gspc_\": \"1. Technicals (S&P500)\",\n",
    "    \"vol_\": \"2. Volatility & Stress\",\n",
    "    \"pcr_\": \"3. Market Internals (PCR)\",\n",
    "    \"breadth_\": \"3. Market Internals (Breadth)\",\n",
    "    \"stk_bond_diff_\": \"4. Intermarket (Stock/Bond Diff)\",\n",
    "    \"spy_tlt_ratio_\": \"4. Intermarket (SPY/TLT Ratio)\",\n",
    "    \"gold_silver_ratio_\": \"4. Intermarket (Gold/Silver Ratio)\",\n",
    "    \"copper_gold_ratio_\": \"4. Intermarket (Copper/Gold Ratio)\",\n",
    "    \"junk_spread_\": \"5. Credit & Bonds (Junk Spread)\",\n",
    "    \"corp_oas_\": \"5. Credit & Bonds (Corp OAS)\",\n",
    "    \"tsy_spread_\": \"5. Credit & Bonds (Treasury Spread)\",\n",
    "    \"em_tbill_spread_\": \"5. Credit & Bonds (EM/T-Bill Spread)\",\n",
    "    \"fg_\": \"6. Sentiment (Fear/Greed)\",\n",
    "    \"conf_\": \"6. Sentiment (Consumer Conf.)\",\n",
    "    \"aaii_\": \"6. Sentiment (AAII)\",\n",
    "    \"finra_\": \"6. Sentiment (FINRA Margin)\",\n",
    "    \"sentconf_\": \"6. Sentiment (SMCI/DMCI)\",\n",
    "    \"nfp_\": \"7. Macro (NFP)\",\n",
    "    \"icj_\": \"7. Macro (Jobless Claims)\",\n",
    "    \"cpi_\": \"7. Macro (CPI)\",\n",
    "    \"retail_\": \"7. Macro (Retail Sales)\",\n",
    "    \"m2_\": \"7. Macro (M2 Supply)\",\n",
    "    \"houst_\": \"7. Macro (Housing Starts)\",\n",
    "    \"hpi_\": \"7. Macro (Housing Prices)\",\n",
    "    \"smi_\": \"8. Market Structure (SMI)\",\n",
    "    \"djt_vs_gspc_\": \"9. Sector/Micro (DJT/GSPC)\",\n",
    "    \"rut_vs_gspc_\": \"9. Sector/Micro (RUT/GSPC)\",\n",
    "    \"qqq_vs_dju_\": \"9. Sector/Micro (QQQ/DJU)\",\n",
    "    \"xlv_vs_gspc_\": \"9. Sector/Micro (XLV/GSPC)\",\n",
    "    \"dxy_\": \"10. Global & Currency (DXY)\",\n",
    "    \"em_\": \"10. Global & Currency (EM Equity)\",\n",
    "    \"oil_\": \"10. Global & Currency (Oil)\",\n",
    "    \"bdi_\": \"10. Global & Currency (BDI)\",\n",
    "    \"gex_\": \"11. Derivatives (GEX)\", \n",
    "    \"sp500_\": \"0. S&P500 Base\",\n",
    "}\n",
    "\n",
    "def get_theme_for_column(col_name, prefix_map):\n",
    "    sorted_prefixes = sorted(prefix_map.keys(), key=len, reverse=True)\n",
    "    for prefix in sorted_prefixes:\n",
    "        if col_name.startswith(prefix):\n",
    "            return prefix_map[prefix]\n",
    "    if col_name.startswith(\"regime_\"):\n",
    "        return \"Market Regime Info\"\n",
    "    return \"Uncategorized\"\n",
    "\n",
    "if not mf_df.empty:\n",
    "    mf_df_numeric = mf_df[numeric_cols] \n",
    "    \n",
    "    features_by_theme = {}\n",
    "    for col in mf_df_numeric.columns:\n",
    "        theme = get_theme_for_column(col, PREFIX_THEME_MAP_FOR_MASTER)\n",
    "        if theme not in features_by_theme:\n",
    "            features_by_theme[theme] = []\n",
    "        features_by_theme[theme].append(col)\n",
    "    \n",
    "    print(\"Feature counts per identified theme:\")\n",
    "    for theme, cols in features_by_theme.items():\n",
    "        print(f\"- {theme}: {len(cols)} features\")\n",
    "    \n",
    "    themes_for_intra_analysis = {theme: cols for theme, cols in features_by_theme.items() if len(cols) >= 2}\n",
    "    print(f\"\\nThemes with >=2 features for intra-analysis: {len(themes_for_intra_analysis)}\")\n",
    "\n",
    "else:\n",
    "    print(\"mf_df is empty. Cannot categorize features by theme.\")\n",
    "    features_by_theme = {}\n",
    "    themes_for_intra_analysis = {}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "37f21efa207f47a1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "INTRA_CATEGORY_DIR = COV_CORR_DIR / \"by_theme\"\n",
    "INTRA_CATEGORY_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not mf_df.empty and themes_for_intra_analysis:\n",
    "    print(f\"\\n--- Generating Intra-Category Covariance & Correlation Matrices ---\")\n",
    "    for theme_name, theme_cols in themes_for_intra_analysis.items(): \n",
    "        print(f\"  Processing theme: {theme_name} ({len(theme_cols)} features)\")\n",
    "        \n",
    "        sanitized_theme_name_for_path = theme_name.replace(\"(\", \"\").replace(\")\", \"\").replace(\"/\", \"_\").replace(\".\", \"\").replace(\"&\", \"and\").replace(\" \", \"_\").lower()\n",
    "        \n",
    "        theme_output_dir = INTRA_CATEGORY_DIR / sanitized_theme_name_for_path\n",
    "        theme_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        temp_df_theme = mf_df_numeric[theme_cols].copy()\n",
    "        \n",
    "        temp_df_theme.dropna(axis=1, how='all', inplace=True)\n",
    "        theme_variances = temp_df_theme.var(ddof=0)\n",
    "        theme_cols_with_variance = theme_variances[theme_variances > 1e-9].index.tolist()\n",
    "        \n",
    "        if len(theme_cols_with_variance) < 2:\n",
    "            print(f\"    Skipping theme '{theme_name}' due to < 2 features with variance.\")\n",
    "            continue\n",
    "            \n",
    "        temp_df_theme_final = temp_df_theme[theme_cols_with_variance]\n",
    "\n",
    "        cov_matrix_theme = temp_df_theme_final.cov()\n",
    "        cov_matrix_theme.to_csv(theme_output_dir / f\"{sanitized_theme_name_for_path}_covariance_matrix.csv\")\n",
    "        \n",
    "        fig_width = max(10, len(theme_cols_with_variance) * 0.4)\n",
    "        fig_height = max(8, len(theme_cols_with_variance) * 0.4)\n",
    "        plt.figure(figsize=(fig_width, fig_height))\n",
    "        sns.heatmap(cov_matrix_theme, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
    "        plt.title(f'Covariance Matrix: {theme_name}', fontsize=16) \n",
    "        plt.xticks(fontsize=8, rotation=90)\n",
    "        plt.yticks(fontsize=8, rotation=0)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(theme_output_dir / f\"{sanitized_theme_name_for_path}_covariance_heatmap.png\")\n",
    "        plt.close()\n",
    "\n",
    "        corr_matrix_theme = temp_df_theme_final.corr()\n",
    "        corr_matrix_theme.to_csv(theme_output_dir / f\"{sanitized_theme_name_for_path}_correlation_matrix.csv\")\n",
    "\n",
    "        plt.figure(figsize=(fig_width, fig_height))\n",
    "        sns.heatmap(corr_matrix_theme, annot=True, cmap='coolwarm', center=0, vmin=-1, vmax=1, fmt=\".2f\", linewidths=.5)\n",
    "        plt.title(f'Correlation Matrix: {theme_name}', fontsize=16)\n",
    "        plt.xticks(fontsize=8, rotation=90)\n",
    "        plt.yticks(fontsize=8, rotation=0)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(theme_output_dir / f\"{sanitized_theme_name_for_path}_correlation_heatmap.png\")\n",
    "        plt.close()\n",
    "        \n",
    "    print(\"Intra-category matrices and heatmaps saved.\")\n",
    "else:\n",
    "    print(\"DataFrame is empty or no themes identified for intra-category analysis.\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f12a2ee9f5a891d1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "INTER_CATEGORY_SUMMARY_DIR = COV_CORR_DIR / \"inter_category_summary\"\n",
    "INTER_CATEGORY_SUMMARY_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not mf_df.empty and themes_for_intra_analysis:\n",
    "    print(f\"\\n--- Generating Inter-Category Average Absolute Correlation Matrix ---\")\n",
    "    \n",
    "    if 'correlation_matrix_full' not in locals() or correlation_matrix_full.empty:\n",
    "        print(\"Full correlation matrix not available. Recomputing for inter-category analysis.\")\n",
    "        if 'cols_with_variance' in locals() and cols_with_variance:\n",
    "            temp_df_for_corr = mf_df_numeric[cols_with_variance]\n",
    "            if not temp_df_for_corr.empty:\n",
    "                correlation_matrix_full = temp_df_for_corr.corr()\n",
    "            else:\n",
    "                print(\"Cannot compute full correlation matrix. Aborting inter-category analysis.\")\n",
    "                correlation_matrix_full = pd.DataFrame()\n",
    "        else:\n",
    "             print(\"cols_with_variance not defined. Cannot compute full correlation matrix. Aborting inter-category analysis.\")\n",
    "             correlation_matrix_full = pd.DataFrame()\n",
    "\n",
    "\n",
    "    if not correlation_matrix_full.empty:\n",
    "        category_names_for_matrix = sorted(list(themes_for_intra_analysis.keys()))\n",
    "        avg_abs_corr_matrix = pd.DataFrame(index=category_names_for_matrix, columns=category_names_for_matrix, dtype=float)\n",
    "\n",
    "        for i, theme1_name in enumerate(category_names_for_matrix):\n",
    "            for j, theme2_name in enumerate(category_names_for_matrix):\n",
    "                if j < i: \n",
    "                    avg_abs_corr_matrix.loc[theme1_name, theme2_name] = avg_abs_corr_matrix.loc[theme2_name, theme1_name]\n",
    "                    continue\n",
    "\n",
    "                cols_theme1 = [col for col in themes_for_intra_analysis[theme1_name] if col in correlation_matrix_full.columns]\n",
    "                cols_theme2 = [col for col in themes_for_intra_analysis[theme2_name] if col in correlation_matrix_full.columns]\n",
    "\n",
    "                if not cols_theme1 or not cols_theme2:\n",
    "                    avg_abs_corr_matrix.loc[theme1_name, theme2_name] = np.nan\n",
    "                    continue\n",
    "                \n",
    "                if theme1_name == theme2_name:\n",
    "                    if len(cols_theme1) < 2:\n",
    "                        avg_abs_corr_matrix.loc[theme1_name, theme1_name] = np.nan\n",
    "                        continue\n",
    "                    sub_corr_matrix = correlation_matrix_full.loc[cols_theme1, cols_theme1]\n",
    "                    upper_triangle_mask = np.triu(np.ones(sub_corr_matrix.shape), k=1).astype(bool)\n",
    "                    relevant_corrs = sub_corr_matrix.where(upper_triangle_mask).stack().abs()\n",
    "                else: \n",
    "                    sub_corr_matrix = correlation_matrix_full.loc[cols_theme1, cols_theme2]\n",
    "                    relevant_corrs = sub_corr_matrix.stack().abs()\n",
    "                \n",
    "                if not relevant_corrs.empty:\n",
    "                    avg_abs_corr_matrix.loc[theme1_name, theme2_name] = relevant_corrs.mean()\n",
    "                else:\n",
    "                    avg_abs_corr_matrix.loc[theme1_name, theme2_name] = np.nan\n",
    "        \n",
    "        avg_abs_corr_matrix.to_csv(INTER_CATEGORY_SUMMARY_DIR / \"inter_category_avg_abs_correlation.csv\")\n",
    "        print(f\"Inter-category average absolute correlation matrix saved to CSV.\")\n",
    "\n",
    "        plt.figure(figsize=(max(12, len(category_names_for_matrix)*0.8), max(10, len(category_names_for_matrix)*0.7)))\n",
    "        sns.heatmap(avg_abs_corr_matrix.astype(float), annot=True, cmap=\"viridis\", fmt=\".2f\", linewidths=.5)\n",
    "        plt.title('Inter-Category Average Absolute Correlation', fontsize=16)\n",
    "        plt.xticks(fontsize=10, rotation=90)\n",
    "        plt.yticks(fontsize=10, rotation=0)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(INTER_CATEGORY_SUMMARY_DIR / \"inter_category_avg_abs_correlation_heatmap.png\")\n",
    "        plt.close()\n",
    "        print(f\"Inter-category average absolute correlation heatmap saved.\")\n",
    "        \n",
    "        print(\"\\n--- Inter-Category Average Absolute Correlation Matrix (Sample) ---\")\n",
    "        display(avg_abs_corr_matrix.head())\n",
    "else:\n",
    "    print(\"DataFrame is empty or no themes for analysis, skipping inter-category correlations.\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d4c14839e8ad16d7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if not mf_df.empty and numeric_cols:\n",
    "    print(f\"\\n--- Generating Univariate Analysis for ALL {len(numeric_cols)} Numeric Columns ---\")\n",
    "\n",
    "    unique_themes_for_dirs = set()\n",
    "    for col in numeric_cols:\n",
    "        theme = get_theme_for_column(col, PREFIX_THEME_MAP_FOR_MASTER)\n",
    "        sanitized_theme_name_for_path = theme.replace(\"(\", \"\").replace(\")\", \"\").replace(\"/\", \"_\").replace(\".\", \"\").replace(\"&\", \"and\").replace(\" \", \"_\").lower()\n",
    "        unique_themes_for_dirs.add(sanitized_theme_name_for_path)\n",
    "    \n",
    "    for sanitized_theme_name in unique_themes_for_dirs:\n",
    "        (UNIVARIATE_DIR / sanitized_theme_name).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "    all_feature_stats = []\n",
    "\n",
    "    for i, col in enumerate(numeric_cols):\n",
    "        print(f\"Processing univariate plots for: {col} ({i+1}/{len(numeric_cols)})\")\n",
    "        \n",
    "        theme = get_theme_for_column(col, PREFIX_THEME_MAP_FOR_MASTER)\n",
    "        sanitized_theme_name_for_path = theme.replace(\"(\", \"\").replace(\")\", \"\").replace(\"/\", \"_\").replace(\".\", \"\").replace(\"&\", \"and\").replace(\" \", \"_\").lower()\n",
    "        col_plot_dir = UNIVARIATE_DIR / sanitized_theme_name_for_path \n",
    "        \n",
    "        feature_series = mf_df[col].dropna()\n",
    "        if feature_series.empty:\n",
    "            print(f\"  Skipping {col} as it contains all NaNs.\")\n",
    "            all_feature_stats.append(pd.Series(name=col, dtype=float)) \n",
    "            continue\n",
    "\n",
    "        all_feature_stats.append(feature_series.describe())\n",
    "\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        sns.histplot(feature_series, kde=True)\n",
    "        plt.title(f'Distribution of {col}')\n",
    "        plt.savefig(col_plot_dir / f\"{col}_distribution.png\")\n",
    "        plt.close()\n",
    "\n",
    "        plt.figure(figsize=(15, 4))\n",
    "        mf_df[col].plot()\n",
    "        plt.title(f'Time Series of {col}')\n",
    "        if 'regime_t' in mf_df.columns and not mf_df['regime_t'].dropna().empty:\n",
    "            regime_data_aligned = mf_df['regime_t'].reindex(feature_series.index).ffill().bfill()\n",
    "            if not regime_data_aligned.dropna().empty:\n",
    "                unique_regimes = sorted(regime_data_aligned.dropna().unique().astype(int))\n",
    "                palette = sns.color_palette(\"viridis\", n_colors=max(3, len(unique_regimes)))\n",
    "                for regime_idx, regime_val in enumerate(unique_regimes):\n",
    "                    if regime_idx < len(palette):\n",
    "                        color_for_regime = palette[regime_idx]\n",
    "                    else: \n",
    "                        color_for_regime = \"gray\" \n",
    "                    \n",
    "                    regime_periods = regime_data_aligned[regime_data_aligned == regime_val]\n",
    "                    if not regime_periods.empty:\n",
    "                        plt.fill_between(regime_periods.index, feature_series.min(), feature_series.max(), \n",
    "                                         where=(regime_data_aligned == regime_val), \n",
    "                                         color=color_for_regime, alpha=0.2, label=f'Regime {int(regime_val)}')\n",
    "                if unique_regimes:\n",
    "                    plt.legend(loc='upper left', bbox_to_anchor=(1,1))\n",
    "        plt.tight_layout() \n",
    "        plt.savefig(col_plot_dir / f\"{col}_timeseries.png\")\n",
    "        plt.close()\n",
    "\n",
    "        if 'regime_t' in mf_df.columns and not mf_df['regime_t'].dropna().empty:\n",
    "            df_for_boxplot = mf_df[[col, 'regime_t']].dropna()\n",
    "            if not df_for_boxplot.empty and len(df_for_boxplot['regime_t'].unique()) > 1:\n",
    "                plt.figure(figsize=(8, 5))\n",
    "                sns.boxplot(x='regime_t', y=col, data=df_for_boxplot, palette='viridis')\n",
    "                plt.title(f'{col} by Regime (regime_t)')\n",
    "                plt.savefig(col_plot_dir / f\"{col}_boxplot_regime.png\")\n",
    "                plt.close()\n",
    "\n",
    "    if all_feature_stats:\n",
    "        all_feature_stats_df = pd.concat(all_feature_stats, axis=1)\n",
    "        all_feature_stats_df.to_csv(UNIVARIATE_DIR / \"all_numeric_features_descriptive_stats.csv\")\n",
    "        print(f\"\\nDescriptive stats for all numeric features saved to: {UNIVARIATE_DIR / 'all_numeric_features_descriptive_stats.csv'}\")\n",
    "else:\n",
    "    print(\"DataFrame is empty or no numeric columns, skipping univariate analysis.\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c666cd4f6b8a011",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "PREFIX_THEME_MAP_FOR_MASTER = {\n",
    "    \"sp500_\": \"0. S&P500 Base Features\",\n",
    "\n",
    "    \"ti_gspc_\": \"1. Technical Trend & Momentum\",\n",
    "\n",
    "    \"vol_\": \"2. Volatility & Market Stress\", \n",
    "\n",
    "    \"pcr_\": \"3. Market Internals\",         \n",
    "    \"breadth_\": \"3. Market Internals\",     \n",
    "\n",
    "    \"stk_bond_diff_\": \"4. Intermarket Relationships\",\n",
    "    \"spy_tlt_ratio_\": \"4. Intermarket Relationships\",\n",
    "    \"gold_silver_ratio_\": \"4. Intermarket Relationships\",\n",
    "    \"copper_gold_ratio_\": \"4. Intermarket Relationships\",\n",
    "    \"djt_vs_gspc_\": \"4. Intermarket Relationships\", \n",
    "    \"rut_vs_gspc_\": \"4. Intermarket Relationships\", \n",
    "\n",
    "    \"junk_spread_\": \"5. Credit & Bond Markets\",\n",
    "    \"corp_oas_\": \"5. Credit & Bond Markets\",\n",
    "    \"tsy_spread_\": \"5. Credit & Bond Markets\", \n",
    "    \"em_tbill_spread_\": \"5. Credit & Bond Markets\",\n",
    "\n",
    "    \"fg_\": \"6. Sentiment & Behavior\",        \n",
    "    \"conf_\": \"6. Sentiment & Behavior\",      \n",
    "    \"aaii_\": \"6. Sentiment & Behavior\",       \n",
    "    \"finra_\": \"6. Sentiment & Behavior\",      \n",
    "    \"sentconf_\": \"6. Sentiment & Behavior\",   \n",
    "\n",
    "    \"nfp_\": \"7. Macro Economic Data\",\n",
    "    \"icj_\": \"7. Macro Economic Data\",\n",
    "    \"cpi_\": \"7. Macro Economic Data\",\n",
    "    \"retail_\": \"7. Macro Economic Data\",\n",
    "    \"m2_\": \"7. Macro Economic Data\",\n",
    "    \"houst_\": \"7. Macro Economic Data\",\n",
    "    \"hpi_\": \"7. Macro Economic Data\",\n",
    "\n",
    "    \"smi_\": \"8. Market Structure & Flows\",    \n",
    "\n",
    "    \"qqq_vs_dju_\": \"9. Sector & Micro Tells\", \n",
    "    \"xlv_vs_gspc_\": \"9. Sector & Micro Tells\",\n",
    "\n",
    "    \"dxy_\": \"10. Global & Currency\",\n",
    "    \"em_\": \"10. Global & Currency\",        \n",
    "    \"oil_\": \"10. Global & Currency\",\n",
    "    \"bdi_\": \"10. Global & Currency\",\n",
    "\n",
    "    \"gex_\": \"11. Derivatives Metrics\",       \n",
    "}\n",
    "\n",
    "def get_theme_for_column(col_name, prefix_map):\n",
    "    sorted_prefixes = sorted(prefix_map.keys(), key=len, reverse=True)\n",
    "    for prefix in sorted_prefixes:\n",
    "        if col_name.startswith(prefix):\n",
    "            return prefix_map[prefix] \n",
    "    if col_name.startswith(\"regime_\"):\n",
    "        return \"Market Regime Info\"\n",
    "    return \"Uncategorized\"\n",
    "\n",
    "if not mf_df.empty:\n",
    "    if 'numeric_cols' not in locals():\n",
    "        numeric_cols = mf_df.select_dtypes(include=np.number).columns.tolist()\n",
    "        \n",
    "    mf_df_numeric = mf_df[numeric_cols] \n",
    "    \n",
    "    features_by_theme = {}\n",
    "    for col in mf_df_numeric.columns:\n",
    "        theme = get_theme_for_column(col, PREFIX_THEME_MAP_FOR_MASTER)\n",
    "        if theme not in features_by_theme:\n",
    "            features_by_theme[theme] = []\n",
    "        features_by_theme[theme].append(col)\n",
    "    \n",
    "    print(\"Feature counts per identified OVERARCHING theme:\")\n",
    "    for theme, cols in sorted(features_by_theme.items()): \n",
    "        print(f\"- {theme}: {len(cols)} features\")\n",
    "    \n",
    "    themes_for_intra_analysis = {theme: cols for theme, cols in features_by_theme.items() if len(cols) >= 2 and theme != \"Uncategorized\"}\n",
    "    print(f\"\\nOverarching themes with >=2 features for intra-analysis: {len(themes_for_intra_analysis)}\")\n",
    "    if \"Uncategorized\" in features_by_theme and len(features_by_theme[\"Uncategorized\"]) > 0:\n",
    "        print(f\"Note: {len(features_by_theme['Uncategorized'])} features were 'Uncategorized'. Review PREFIX_THEME_MAP_FOR_MASTER if this is not expected.\")\n",
    "        print(f\"  Sample uncategorized: {features_by_theme['Uncategorized'][:5]}\")\n",
    "\n",
    "\n",
    "else:\n",
    "    print(\"mf_df is empty. Cannot categorize features by theme.\")\n",
    "    features_by_theme = {}\n",
    "    themes_for_intra_analysis = {}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2549881b8722bbbf",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "INTRA_CATEGORY_DIR = COV_CORR_DIR / \"by_theme\"\n",
    "INTRA_CATEGORY_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not mf_df.empty and themes_for_intra_analysis:\n",
    "    print(f\"\\n--- Generating Intra-Category Covariance & Correlation Matrices (Based on Overarching Themes) ---\")\n",
    "    for theme_name, theme_cols in themes_for_intra_analysis.items(): \n",
    "        print(f\"  Processing theme: {theme_name} ({len(theme_cols)} features)\")\n",
    "        \n",
    "        sanitized_theme_name_for_path = theme_name.replace(\"(\", \"\").replace(\")\", \"\").replace(\"/\", \"_\").replace(\".\", \"\").replace(\"&\", \"and\").replace(\" \", \"_\").lower()\n",
    "        \n",
    "        theme_output_dir = INTRA_CATEGORY_DIR / sanitized_theme_name_for_path\n",
    "        theme_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        temp_df_theme = mf_df_numeric[theme_cols].copy()\n",
    "        \n",
    "        temp_df_theme.dropna(axis=1, how='all', inplace=True)\n",
    "        theme_variances = temp_df_theme.var(ddof=0)\n",
    "        theme_cols_with_variance = theme_variances[theme_variances > 1e-9].index.tolist()\n",
    "        \n",
    "        if len(theme_cols_with_variance) < 2:\n",
    "            print(f\"    Skipping theme '{theme_name}' due to < 2 features with variance.\")\n",
    "            continue\n",
    "            \n",
    "        temp_df_theme_final = temp_df_theme[theme_cols_with_variance]\n",
    "\n",
    "        cov_matrix_theme = temp_df_theme_final.cov()\n",
    "        cov_matrix_theme.to_csv(theme_output_dir / f\"{sanitized_theme_name_for_path}_covariance_matrix.csv\")\n",
    "        \n",
    "        fig_width = max(10, len(theme_cols_with_variance) * 0.4)\n",
    "        fig_height = max(8, len(theme_cols_with_variance) * 0.4)\n",
    "        plt.figure(figsize=(fig_width, fig_height))\n",
    "        sns.heatmap(cov_matrix_theme, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
    "        plt.title(f'Covariance Matrix: {theme_name}', fontsize=16) \n",
    "        plt.xticks(fontsize=max(6, 10 - len(theme_cols_with_variance)//5), rotation=90) \n",
    "        plt.yticks(fontsize=max(6, 10 - len(theme_cols_with_variance)//5), rotation=0)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(theme_output_dir / f\"{sanitized_theme_name_for_path}_covariance_heatmap.png\")\n",
    "        plt.close()\n",
    "\n",
    "        corr_matrix_theme = temp_df_theme_final.corr()\n",
    "        corr_matrix_theme.to_csv(theme_output_dir / f\"{sanitized_theme_name_for_path}_correlation_matrix.csv\")\n",
    "\n",
    "        plt.figure(figsize=(fig_width, fig_height))\n",
    "        sns.heatmap(corr_matrix_theme, annot=True, cmap='coolwarm', center=0, vmin=-1, vmax=1, fmt=\".2f\", linewidths=.5) \n",
    "        plt.title(f'Correlation Matrix: {theme_name}', fontsize=16)\n",
    "        plt.xticks(fontsize=max(6, 10 - len(theme_cols_with_variance)//5), rotation=90)\n",
    "        plt.yticks(fontsize=max(6, 10 - len(theme_cols_with_variance)//5), rotation=0)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(theme_output_dir / f\"{sanitized_theme_name_for_path}_correlation_heatmap.png\")\n",
    "        plt.close()\n",
    "        \n",
    "    print(\"Intra-category matrices and heatmaps saved.\")\n",
    "else:\n",
    "    print(\"DataFrame is empty or no themes identified for intra-category analysis.\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f61bf2c2eed4b2a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if not mf_df.empty and numeric_cols:\n",
    "    print(f\"\\n--- Generating Univariate Analysis for ALL {len(numeric_cols)} Numeric Columns (Grouped by Overarching Theme) ---\")\n",
    "    \n",
    "    unique_themes_for_dirs = set()\n",
    "    for col in numeric_cols:\n",
    "        theme = get_theme_for_column(col, PREFIX_THEME_MAP_FOR_MASTER)\n",
    "        sanitized_theme_name_for_path = theme.replace(\"(\", \"\").replace(\")\", \"\").replace(\"/\", \"_\").replace(\".\", \"\").replace(\"&\", \"and\").replace(\" \", \"_\").lower()\n",
    "        unique_themes_for_dirs.add(sanitized_theme_name_for_path)\n",
    "    \n",
    "    for sanitized_theme_name in unique_themes_for_dirs:\n",
    "        (UNIVARIATE_DIR / sanitized_theme_name).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    all_feature_stats = []\n",
    "\n",
    "    for i, col in enumerate(numeric_cols):\n",
    "        print(f\"Processing univariate plots for: {col} ({i+1}/{len(numeric_cols)})\")\n",
    "        \n",
    "        theme = get_theme_for_column(col, PREFIX_THEME_MAP_FOR_MASTER)\n",
    "        sanitized_theme_name_for_path = theme.replace(\"(\", \"\").replace(\")\", \"\").replace(\"/\", \"_\").replace(\".\", \"\").replace(\"&\", \"and\").replace(\" \", \"_\").lower()\n",
    "        col_plot_dir = UNIVARIATE_DIR / sanitized_theme_name_for_path\n",
    "        \n",
    "        feature_series = mf_df[col].dropna()\n",
    "        if feature_series.empty:\n",
    "            print(f\"  Skipping {col} as it contains all NaNs.\")\n",
    "            all_feature_stats.append(pd.Series(name=col, dtype=float)) \n",
    "            continue\n",
    "\n",
    "        all_feature_stats.append(feature_series.describe())\n",
    "\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        sns.histplot(feature_series, kde=True)\n",
    "        plt.title(f'Distribution of {col}\\n(Theme: {theme})')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(col_plot_dir / f\"{col}_distribution.png\")\n",
    "        plt.close()\n",
    "\n",
    "        plt.figure(figsize=(15, 4))\n",
    "        mf_df[col].plot()\n",
    "        plt.title(f'Time Series of {col}\\n(Theme: {theme})')\n",
    "        if 'regime_t' in mf_df.columns and not mf_df['regime_t'].dropna().empty:\n",
    "            regime_data_aligned = mf_df['regime_t'].reindex(feature_series.index).ffill().bfill()\n",
    "            if not regime_data_aligned.dropna().empty:\n",
    "                unique_regimes = sorted(regime_data_aligned.dropna().unique().astype(int))\n",
    "                palette = sns.color_palette(\"viridis\", n_colors=max(3, len(unique_regimes)))\n",
    "                for regime_idx, regime_val in enumerate(unique_regimes):\n",
    "                    if regime_idx < len(palette):\n",
    "                        color_for_regime = palette[regime_idx]\n",
    "                    else: \n",
    "                        color_for_regime = \"gray\" \n",
    "                    \n",
    "                    regime_periods = regime_data_aligned[regime_data_aligned == regime_val]\n",
    "                    if not regime_periods.empty:\n",
    "                        plt.fill_between(regime_periods.index, feature_series.min(), feature_series.max(), \n",
    "                                         where=(regime_data_aligned == regime_val), \n",
    "                                         color=color_for_regime, alpha=0.2, label=f'Regime {int(regime_val)}')\n",
    "                if unique_regimes:\n",
    "                    plt.legend(loc='upper left', bbox_to_anchor=(1,1))\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(col_plot_dir / f\"{col}_timeseries.png\")\n",
    "        plt.close()\n",
    "\n",
    "        if 'regime_t' in mf_df.columns and not mf_df['regime_t'].dropna().empty:\n",
    "            df_for_boxplot = mf_df[[col, 'regime_t']].dropna()\n",
    "            if not df_for_boxplot.empty and len(df_for_boxplot['regime_t'].unique()) > 1:\n",
    "                plt.figure(figsize=(8, 5))\n",
    "                sns.boxplot(x='regime_t', y=col, data=df_for_boxplot, palette='viridis')\n",
    "                plt.title(f'{col} by Regime (regime_t)\\n(Theme: {theme})')\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(col_plot_dir / f\"{col}_boxplot_regime.png\")\n",
    "                plt.close()\n",
    "\n",
    "    if all_feature_stats:\n",
    "        all_feature_stats_df = pd.concat(all_feature_stats, axis=1)\n",
    "        all_feature_stats_df.to_csv(UNIVARIATE_DIR / \"all_numeric_features_descriptive_stats.csv\")\n",
    "        print(f\"\\nDescriptive stats for all numeric features saved to: {UNIVARIATE_DIR / 'all_numeric_features_descriptive_stats.csv'}\")\n",
    "else:\n",
    "    print(\"DataFrame is empty or no numeric columns, skipping univariate analysis.\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4cd0387d9c250d5c",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7. Analysis of Vintage Data Lags\n",
    "For each feature with a `_ref_date`, calculate and plot the distribution of its data lag.\n",
    "Summaries and plots will be saved to `data/reports/eda/master_features/vintage_lag_analysis/`."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bed5b56a7df1aea9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if not mf_df.empty:\n",
    "    vintage_ref_date_cols = [col for col in mf_df.columns if col.endswith('_ref_date')]\n",
    "    print(f\"\\n--- Analysis of Vintage Data Lags for: {vintage_ref_date_cols} ---\")\n",
    "    \n",
    "    all_lag_stats = {}\n",
    "\n",
    "    for ref_col in vintage_ref_date_cols:\n",
    "        if ref_col in mf_df.columns and mf_df[ref_col].notna().any():\n",
    "            try:\n",
    "                feature_ref_dates = pd.to_datetime(mf_df[ref_col], errors='coerce')\n",
    "                \n",
    "                valid_ref_dates_mask = feature_ref_dates.notna()\n",
    "                lags = (mf_df.index[valid_ref_dates_mask].to_series() - feature_ref_dates[valid_ref_dates_mask]).dt.days\n",
    "                lags = lags.dropna()\n",
    "\n",
    "                if not lags.empty:\n",
    "                    print(f\"  Processing lags for {ref_col}...\")\n",
    "                    plt.figure(figsize=(10, 4))\n",
    "                    sns.histplot(lags, kde=False, bins=min(50, lags.nunique())) # Adjust bins\n",
    "                    plt.title(f'Distribution of Data Lag for {ref_col} (in days)')\n",
    "                    plt.xlabel('Lag (Days)')\n",
    "                    plt.ylabel('Frequency')\n",
    "                    plt.tight_layout()\n",
    "                    plt.savefig(VINTAGE_LAG_DIR / f\"lag_distribution_{ref_col}.png\")\n",
    "                    plt.close()\n",
    "                    \n",
    "                    lag_desc = lags.describe()\n",
    "                    all_lag_stats[ref_col] = lag_desc\n",
    "                    print(f\"    Summary statistics for lag of '{ref_col}':\")\n",
    "                    display(lag_desc)\n",
    "                else:\n",
    "                    print(f\"  No valid lag data to plot for {ref_col} (all NaNs or empty after processing).\")\n",
    "            except Exception as e:\n",
    "                print(f\"  Error processing lags for {ref_col}: {e}\")\n",
    "        else:\n",
    "            print(f\"  Column {ref_col} not found or all NaNs, skipping lag analysis.\")\n",
    "    \n",
    "    if all_lag_stats:\n",
    "        all_lag_stats_df = pd.DataFrame(all_lag_stats)\n",
    "        all_lag_stats_df.to_csv(VINTAGE_LAG_DIR / \"all_vintage_lag_summary_stats.csv\")\n",
    "        print(f\"\\nVintage lag summary stats saved to: {VINTAGE_LAG_DIR / 'all_vintage_lag_summary_stats.csv'}\")\n",
    "else:\n",
    "    print(\"DataFrame is empty, skipping vintage data lag analysis.\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b6b89766fce811e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1a6c49b16839670f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
