{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import re\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(\"Combined_Model_Experiments\")\n",
    "\n",
    "required_packages = {\n",
    "    \"catboost\": \"catboost\",\n",
    "    \"lightgbm\": \"lightgbm\",\n",
    "    \"xgboost\": \"xgboost\",\n",
    "    \"pandas\": \"pandas\",\n",
    "    \"numpy\": \"numpy\",\n",
    "    \"matplotlib\": \"matplotlib\",\n",
    "    \"seaborn\": \"seaborn\",\n",
    "    \"sklearn\": \"scikit-learn\",\n",
    "    \"IPython\": \"ipython\",\n",
    "    \"yaml\": \"pyyaml\" \n",
    "}\n",
    "\n",
    "for package_name, install_name in required_packages.items():\n",
    "    try:\n",
    "        __import__(package_name)\n",
    "        logger.info(f\"Package '{package_name}' is already installed.\")\n",
    "    except ImportError:\n",
    "        logger.warning(f\"Module '{package_name}' not found. Attempting to install '{install_name}'...\")\n",
    "        try:\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", install_name])\n",
    "            logger.info(f\"Package '{install_name}' installed successfully.\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to install '{install_name}': {e}\")\n",
    "            logger.error(f\"Please install it manually in your environment (e.g., `pip install {install_name}`) and restart the Jupyter kernel.\")\n",
    "            raise\n",
    "\n",
    "# --- Now, we can safely import everything ---\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# --- Project Path Setup ---\n",
    "PROJECT_ROOT_PATH = Path.cwd().parent\n",
    "if str(PROJECT_ROOT_PATH) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT_PATH))\n",
    "\n",
    "from regime_predictor_lib.utils.database_manager import DatabaseManager\n",
    "from regime_predictor_lib.supervised_learning.models import CatBoostModel, XGBoostModel\n",
    "from regime_predictor_lib.supervised_learning.evaluation import get_sklearn_classification_report, get_sklearn_confusion_matrix\n",
    "from regime_predictor_lib.supervised_learning.results.result_saver import ResultSaver\n",
    "from regime_predictor_lib.supervised_learning.results import plotting_utils\n",
    "from regime_predictor_lib.supervised_learning.training.trainer import ModelTrainer\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "sns.set_context(\"notebook\") \n",
    "plt.rcParams[\"figure.figsize\"] = (12, 7)\n",
    "plt.rcParams[\"figure.dpi\"] = 90\n",
    "\n",
    "DB_PATH = PROJECT_ROOT_PATH / \"data\" / \"db\" / \"volume\" / \"quant.db\"\n",
    "DEFAULT_MODEL_PARAMS_PATH = PROJECT_ROOT_PATH / \"config\" / \"supervised_learning\" / \"default_model_params.yaml\"\n",
    "THEMATIC_FEATURE_LISTS_DIR = PROJECT_ROOT_PATH / \"data\" / \"processed\" / \"feature_selection\" / \"thematic_feature_lists\"\n",
    "RESULTS_SUMMARY_PATH = PROJECT_ROOT_PATH / \"data\" / \"reports\" / \"supervised_learning\" / \"master_results_summary.csv\"\n",
    "BASE_REPORT_DIR = PROJECT_ROOT_PATH / \"data\" / \"reports\" / \"supervised_learning\" / \"combined_models\"\n",
    "BASE_MODEL_DIR = PROJECT_ROOT_PATH / \"data\" / \"models\" / \"supervised\" / \"combined_models\"\n",
    "\n",
    "db_manager = DatabaseManager(db_path=DB_PATH)\n",
    "result_saver = ResultSaver(base_report_dir=BASE_REPORT_DIR, base_model_dir=BASE_MODEL_DIR)\n",
    "\n",
    "with open(DEFAULT_MODEL_PARAMS_PATH, 'r') as f:\n",
    "    default_model_params = yaml.safe_load(f)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ecbfc5099a1e254",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup_and_imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import re\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "PROJECT_ROOT_PATH = Path.cwd().parent\n",
    "if str(PROJECT_ROOT_PATH) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT_PATH))\n",
    "\n",
    "from regime_predictor_lib.utils.database_manager import DatabaseManager\n",
    "from regime_predictor_lib.supervised_learning.models import CatBoostModel, XGBoostModel\n",
    "from regime_predictor_lib.supervised_learning.evaluation import get_sklearn_classification_report, get_sklearn_confusion_matrix\n",
    "from regime_predictor_lib.supervised_learning.results.result_saver import ResultSaver\n",
    "from regime_predictor_lib.supervised_learning.results import plotting_utils\n",
    "from regime_predictor_lib.supervised_learning.training.trainer import ModelTrainer\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "sns.set_context(\"notebook\") \n",
    "plt.rcParams[\"figure.figsize\"] = (12, 7)\n",
    "plt.rcParams[\"figure.dpi\"] = 90\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(\"Combined_Model_Experiments\")\n",
    "\n",
    "DB_PATH = PROJECT_ROOT_PATH / \"data\" / \"db\" / \"volume\" / \"quant.db\"\n",
    "DEFAULT_MODEL_PARAMS_PATH = PROJECT_ROOT_PATH / \"config\" / \"supervised_learning\" / \"default_model_params.yaml\"\n",
    "THEMATIC_FEATURE_LISTS_DIR = PROJECT_ROOT_PATH / \"data\" / \"processed\" / \"feature_selection\" / \"thematic_feature_lists\"\n",
    "RESULTS_SUMMARY_PATH = PROJECT_ROOT_PATH / \"data\" / \"reports\" / \"supervised_learning\" / \"master_results_summary.csv\"\n",
    "BASE_REPORT_DIR = PROJECT_ROOT_PATH / \"data\" / \"reports\" / \"supervised_learning\" / \"combined_models\"\n",
    "BASE_MODEL_DIR = PROJECT_ROOT_PATH / \"data\" / \"models\" / \"supervised\" / \"combined_models\"\n",
    "\n",
    "db_manager = DatabaseManager(db_path=DB_PATH)\n",
    "result_saver = ResultSaver(base_report_dir=BASE_REPORT_DIR, base_model_dir=BASE_MODEL_DIR)\n",
    "\n",
    "with open(DEFAULT_MODEL_PARAMS_PATH, 'r') as f:\n",
    "    default_model_params = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rank_themes",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Loading and ranking thematic model results...\")\n",
    "results_df = pd.read_csv(RESULTS_SUMMARY_PATH)\n",
    "theme_scores = results_df.groupby('theme')['f1_macro_mean'].mean().sort_values(ascending=False)\n",
    "ranked_themes = theme_scores.index.tolist()\n",
    "display(Markdown(\"### Ranked Thematic Models (by F1 Macro Mean)\"))\n",
    "display(theme_scores.to_frame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "define_pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment_pipeline(top_n_themes: list, model_class, model_name: str, model_params: dict, include_regime_t: bool, shared_label_encoder) -> dict:\n",
    "    experiment_name = f\"Top{len(top_n_themes)}_{'WithRegimeT' if include_regime_t else 'NoRegimeT'}\"\n",
    "    logger.info(f\"--- Running pipeline for {model_name} on {experiment_name} ---\")\n",
    "    \n",
    "    feature_dfs = []\n",
    "    for theme_name in top_n_themes:\n",
    "        try:\n",
    "            theme_table_name = f\"theme_{theme_name.split('theme_')[-1]}\"\n",
    "            df_theme = pd.read_sql_table(theme_table_name, db_manager.engine, index_col=\"date\", parse_dates=[\"date\"])\n",
    "            \n",
    "            feature_list_path = THEMATIC_FEATURE_LISTS_DIR / f\"{theme_table_name}_selected_features.txt\"\n",
    "            with open(feature_list_path, \"r\") as f:\n",
    "                features_for_theme = [line.strip() for line in f if line.strip()]\n",
    "            \n",
    "            feature_dfs.append(df_theme[features_for_theme])\n",
    "            logger.debug(f\"Loaded {len(features_for_theme)} features for {theme_name}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Could not load data for theme '{theme_name}': {e}\")\n",
    "            continue\n",
    "\n",
    "    if not feature_dfs:\n",
    "        logger.error(\"No feature DataFrames were loaded. Aborting pipeline.\")\n",
    "        return {}\n",
    "        \n",
    "    X = pd.concat(feature_dfs, axis=1)\n",
    "    X = X.loc[:, ~X.columns.duplicated()]\n",
    "    \n",
    "    ref_theme_table_name = f\"theme_{top_n_themes[0].split('theme_')[-1]}\"\n",
    "    df_ref = pd.read_sql_table(ref_theme_table_name, db_manager.engine, index_col=\"date\", parse_dates=[\"date\"])\n",
    "    \n",
    "    y = df_ref['regime_t_plus_6m']\n",
    "    \n",
    "    if include_regime_t:\n",
    "        if 'regime_t' in df_ref.columns:\n",
    "            X['regime_t'] = df_ref['regime_t']\n",
    "        else:\n",
    "            logger.warning(\"'regime_t' not found in reference table, cannot add as feature.\")\n",
    "    \n",
    "    common_index = X.index.intersection(y.index).sort_values()\n",
    "    X, y = X.loc[common_index], y.loc[common_index]\n",
    "    X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    X.ffill(inplace=True)\n",
    "    X.dropna(axis=1, how='all', inplace=True) \n",
    "    X.fillna(0, inplace=True) \n",
    "    \n",
    "    y.dropna(inplace=True)\n",
    "    final_index = X.index.intersection(y.index)\n",
    "    X, y = X.loc[final_index], y.loc[final_index]\n",
    "    \n",
    "    logger.info(f\"Final dataset shape: X={X.shape}, y={y.shape}\")\n",
    "    \n",
    "    y_encoded = pd.Series(shared_label_encoder.transform(y), index=y.index, name=y.name)\n",
    "    \n",
    "    model_wrapper = model_class(model_params=model_params)\n",
    "    cv_splitter = TimeSeriesSplit(n_splits=5)\n",
    "    \n",
    "    trainer = ModelTrainer(\n",
    "        model_wrapper=model_wrapper, \n",
    "        cv_splitter=cv_splitter, \n",
    "        scorers={}, \n",
    "        result_saver=result_saver,\n",
    "        theme_name=experiment_name, \n",
    "        model_config_name=model_name,\n",
    "        label_encoder=shared_label_encoder\n",
    "    )\n",
    "    \n",
    "    aggregated_metrics = trainer.run_cross_validation(X, y_encoded, use_class_weights=True)\n",
    "    \n",
    "    display(Markdown(f\"### Results for {model_name} on {experiment_name}\"))\n",
    "    oof_df = trainer.oof_predictions\n",
    "    y_true_oof = oof_df['true_label']\n",
    "    y_pred_oof = oof_df['predicted_label']\n",
    "    class_names = [f'Regime {c}' for c in shared_label_encoder.classes_]\n",
    "    \n",
    "    print(\"\\n--- Classification Report (Out-of-Fold) ---\")\n",
    "    print(get_sklearn_classification_report(y_true_oof, y_pred_oof, target_names=class_names))\n",
    "    \n",
    "    cm = get_sklearn_confusion_matrix(y_true_oof, y_pred_oof)\n",
    "    fig_cm = plotting_utils.plot_confusion_matrix(cm, class_names, f\"Confusion Matrix - {model_name} on {experiment_name}\", normalize=True)\n",
    "    plt.show()\n",
    "    \n",
    "    final_model = trainer.train_final_model(X, y_encoded)\n",
    "    feature_importances = final_model.get_feature_importance()\n",
    "    \n",
    "    return {\n",
    "        \"metrics\": aggregated_metrics,\n",
    "        \"feature_importances\": feature_importances,\n",
    "        \"n_features\": len(X.columns)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run_exp1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_without_regime_t = {}\n",
    "model_types_to_run = [\"xgboost\", \"catboost\"]\n",
    "\n",
    "y_master = pd.read_sql_table(\"theme_simple_technical_trend_and_momentum_signals\", db_manager.engine, index_col=\"date\", parse_dates=[\"date\"])['regime_t_plus_6m'].dropna()\n",
    "shared_label_encoder = LabelEncoder().fit(y_master.unique())\n",
    "logger.info(f\"Shared LabelEncoder fitted on all potential target values. Classes: {shared_label_encoder.classes_}\")\n",
    "\n",
    "for n in range(2, len(ranked_themes) + 1):\n",
    "    top_n = ranked_themes[:n]\n",
    "    key = f\"top_{n}\"\n",
    "    results_without_regime_t[key] = {}\n",
    "    \n",
    "    for model_name in model_types_to_run:\n",
    "        results_without_regime_t[key][model_name] = run_experiment_pipeline(\n",
    "            top_n_themes=top_n,\n",
    "            model_class=XGBoostModel if model_name == 'xgboost' else CatBoostModel,\n",
    "            model_name=model_name.capitalize(),\n",
    "            model_params=default_model_params[model_name],\n",
    "            include_regime_t=False,\n",
    "            shared_label_encoder=shared_label_encoder\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run_exp2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_with_regime_t = {}\n",
    "\n",
    "for n in range(2, len(ranked_themes) + 1):\n",
    "    top_n = ranked_themes[:n]\n",
    "    key = f\"top_{n}\"\n",
    "    results_with_regime_t[key] = {}\n",
    "    \n",
    "    for model_name in model_types_to_run:\n",
    "        results_with_regime_t[key][model_name] = run_experiment_pipeline(\n",
    "            top_n_themes=top_n,\n",
    "            model_class=XGBoostModel if model_name == 'xgboost' else CatBoostModel,\n",
    "            model_name=model_name.capitalize(),\n",
    "            model_params=default_model_params[model_name],\n",
    "            include_regime_t=True,\n",
    "            shared_label_encoder=shared_label_encoder\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meta_analysis_plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_metrics(results_dict, metric_key='f1_macro_mean'):\n",
    "    data = []\n",
    "    for top_n_key, model_results in results_dict.items():\n",
    "        n_themes = int(top_n_key.split('_')[-1])\n",
    "        for model_name, result in model_results.items():\n",
    "            if result and 'metrics' in result and metric_key in result['metrics']:\n",
    "                data.append({\n",
    "                    'n_themes': n_themes,\n",
    "                    'model': model_name,\n",
    "                    'metric_value': result['metrics'][metric_key]\n",
    "                })\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "metrics_no_regime_t = extract_metrics(results_without_regime_t)\n",
    "metrics_with_regime_t = extract_metrics(results_with_regime_t)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "\n",
    "sns.lineplot(data=metrics_no_regime_t, x='n_themes', y='metric_value', hue='model', ax=ax, marker='o', linestyle='-')\n",
    "sns.lineplot(data=metrics_with_regime_t, x='n_themes', y='metric_value', hue='model', ax=ax, marker='x', linestyle='--')\n",
    "\n",
    "ax.set_title('Model Performance vs. Number of Combined Thematic Feature Sets', fontsize=18)\n",
    "ax.set_xlabel('Number of Top-Ranked Themes Included', fontsize=14)\n",
    "ax.set_ylabel('Out-of-Fold F1 Macro (Mean)', fontsize=14)\n",
    "ax.set_xticks(range(2, len(ranked_themes) + 1))\n",
    "ax.grid(True, which='both', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Improve legend\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "new_labels = [\n",
    "    'XGBoost (No regime_t)', 'CatBoost (No regime_t)',\n",
    "    'XGBoost (With regime_t)', 'CatBoost (With regime_t)'\n",
    "]\n",
    "ax.legend(handles, new_labels, title='Experiment', fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature_importance_rollup",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_theme_from_feature_name(feature_name):\n",
    "    match = re.match(r'^([a-z_]+)_', feature_name)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return 'unknown'\n",
    "\n",
    "all_themes_key = f\"top_{len(ranked_themes)}\"\n",
    "\n",
    "for model_name in model_types_to_run:\n",
    "    if all_themes_key in results_without_regime_t and model_name in results_without_regime_t[all_themes_key]:\n",
    "        run_results = results_without_regime_t[all_themes_key][model_name]\n",
    "        if run_results and 'feature_importances' in run_results:\n",
    "            fi_series = run_results['feature_importances']\n",
    "            fi_df = fi_series.to_frame(name='importance').reset_index().rename(columns={'index':'feature'})\n",
    "            fi_df['theme_group'] = fi_df['feature'].apply(get_theme_from_feature_name)\n",
    "            \n",
    "            theme_importance = fi_df.groupby('theme_group')['importance'].sum().sort_values(ascending=False)\n",
    "            theme_importance_pct = (theme_importance / theme_importance.sum()) * 100\n",
    "            \n",
    "            fig, ax = plt.subplots(figsize=(14, 8))\n",
    "            sns.barplot(x=theme_importance_pct.index, y=theme_importance_pct.values, ax=ax)\n",
    "            ax.set_title(f'Thematic Feature Importance Roll-up for {model_name.capitalize()} (All Features)', fontsize=16)\n",
    "            ax.set_ylabel('Percentage of Total Importance (%)', fontsize=12)\n",
    "            ax.set_xlabel('Feature Theme Group', fontsize=12)\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
